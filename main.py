import json
from io import BytesIO

import cv2
import numpy as np
from PIL import Image
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.models import Model
import base64

# 1. VGG16 ëª¨ë¸ (conv5_block3_conv3 ë ˆì´ì–´ê¹Œì§€ ê°€ì ¸ì˜¤ê¸°)
base_model = VGG16(weights="imagenet", include_top=False)
layer_name = "block5_conv3"  # ë§ˆì§€ë§‰ Conv Layer
model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)

app = FastAPI()

@app.get("/")
async def root():
    return {"message": "Hello World"}

@app.post("/process-image/")
async def process_image(file: UploadFile = File(...)):
    image_data = await file.read()
    np_image = np.frombuffer(image_data, np.uint8)
    image = cv2.imdecode(np_image, cv2.IMREAD_COLOR)
    img = load_and_preprocess_image(image)  # ë³€í™˜ëœ NumPy ë°°ì—´ ì‚¬ìš©

    features = extract_features(img)  # byte[] , ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì 
    order = extract_feature_means_sort(img)  # ë¬¸ìì—´, í¬ê¸°ìˆœìœ¼ë¡œ ì •ë ¬ëœ ë ˆì´ì–´ ë²ˆí˜¸

    # ğŸ”¥ featuresë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜
    features_base64 = base64.b64encode(features).decode("utf-8")

    return JSONResponse(content={"order": order, "features": features_base64})

# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (íŒŒì¼ ê²½ë¡œ ëŒ€ì‹  PIL ì´ë¯¸ì§€ë¥¼ ë°›ë„ë¡ ìˆ˜ì •)
def load_and_preprocess_image(image: Image.Image):
    img = np.array(image)  # PIL ì´ë¯¸ì§€ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # RGB â†’ BGR ë³€í™˜ (OpenCV ì‚¬ìš©)
    img = cv2.resize(img, (224, 224))  # ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    return img


# 3. ê° ë ˆì´ì–´ì˜ Intensity ê°’ì´ í° ìˆœì„œëŒ€ë¡œ ì •ë ¬
def extract_feature_means_sort(img):

    feature_maps = model.predict(img)  # (1, 14, 14, 512) í˜•íƒœ
    feature_maps = feature_maps.squeeze()  # (14, 14, 512)ë¡œ ë³€í™˜

    # ê° ë ˆì´ì–´ì˜ í‰ê·  Intensity ê³„ì‚°
    feature_dict = {
        f"{i + 1}": np.mean(feature_maps[:, :, i]) for i in range(512)
    }

    # ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ìƒìœ„ 25ê°œ ì„ íƒ
    sorted_features = sorted(feature_dict.items(), key=lambda x: x[1], reverse=True)
    layer_numbers = [int(layer) for layer, _ in sorted_features[:25]]
    json_data = json.dumps(layer_numbers)
    print(json_data)

    return json.dumps(layer_numbers)  # JSON ë¬¸ìì—´ ë³€í™˜ í›„ ë°˜í™˜

# 4. ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì  ì¶”ì¶œ ë° ì´ì§„í™”
def extract_features(img):

    features = base_model.predict(img).flatten()  # 1D ë²¡í„° ë³€í™˜

    # 0ì„ ì œì™¸í•œ ê°’ë“¤ì˜ í‰ê·  ê³„ì‚°
    nonzero_features = features[features != 0]
    mean_value = np.mean(nonzero_features) if len(nonzero_features) > 0 else 0

    # ì´ì§„í™”: í‰ê·  ì´ìƒì´ë©´ 1, ë¯¸ë§Œì´ë©´ 0
    binary_features = np.where(features >= mean_value, 1, 0)
    binary_bytes = np.packbits(binary_features).tobytes()  # NumPy ë°°ì—´ì„ bytesë¡œ ë³€í™˜
    #print(f" ì´ì§„í™”ëœ íŠ¹ì§•ì  ì¼ë¶€: {binary_features[:100]}")
    return binary_bytes
